What?
	搭建Inferno下的集群以及实现在Inferno下的并行计算框架
	我们要全平台支持，包括硬件平台和软件平台。Inferno自身支持x86,amd64,arm,sparc,powerpc等多种架构。且Inferno提供了两种运行方式hosted和native.其中native是原生态的运行在硬件上，而hosted则是个应用层虚拟化，可以使Inferno运行在其他操作系统之上。利用以上两点，我们可以搭建一个由各种平台环境的节点组成的集群。而这一切对于程序员来说又是透明的，我们只需实现在Inferno下的并行框架，他就具有跨平台性。
	我们做的并行计算框架可以做到跨节点计算能力。节点之间的计算能力可以差别加到，例如我们的框架可以在树莓派和服务器这两个计算能力差别较大的环境下并行执行。
	我们的并行框架要做到易于使用。后期我们将定义一套APP规范，用户只要按照规范实现则可轻松并行化执行。

Why?
	良好的易购性。当今异构支持较好的并行计算框架有CUDA和OpenCL.对于并行计算领域，异构仍然是个难题。
	充分发挥了分布式操作系统的强大之处。分布式操作系统是个很伟大的idea,它可以通过网络将多个设备连接在一起而在外界看来就好像是一台电脑。我们做的并行框架充分地利用了分布式网络系统的强大之处，将各个节点连接在一起进行并行计算取得良好的加速比，从实践角度展示了分布式os的强大威力。
	良好的经济效益，设想我们可能会有废旧的闲置的个人PC亦或是闲置的arm架构的手机。只要在他们上部署了Inferno，我们都可以拿他们作为节点，接入集群加速计算。从而做到物尽其用，取得良好的经济效益。
	选题新颖。根据调研，尚未有人在Inferno上做过并行计算框架。而且Inferno的资料少之又少，文档也很不完整，只有官方网站提供少许资料，进一步的资料还要收钱，几乎没人在Inferno上开发应用程序。我们的选题实属首创。

Why?
	经过调研，为了充分展示其跨平台性，我们决定使用Hosted模式.并准备最终在arm架构的设备以及笔记本电脑，高性能服务器上实现并行计算。经过调研最终决定选择Raspberry Pi.笔记本电脑我们组共有4台，服务器由于这学期我在超算队做系统管理，手下管着十余个高性能服务器节点。笔记本电脑和服务器都是64位的，虽然Inferno官方之提供了对32位的支持，但是经过稍加修改以及成功在64位上运行了。至于arm架构，官方本来是提供支持的，但是Inferno这个项目已经停滞很久了，很多开发都跟不上。arm版本的代码以及完全无法在现在的机子上运行。我首先再自己电脑上搭建了arm交叉编译链，再一遍根据硬件手册，一遍修改代码。在此期间，我联系了Inferno官方开发组和他们一起协同处理问题。我还报了2个bug给官方，一个被标为critical级别，一个被标为major级别。还给官方提交了一个patch.最终经过努力成功在Raspberry Pi上运行了。
	经过调研了各种其他并行计算框架，平台模型我们决定仿照OpenCL的host & device模式.host & device 模式非常成熟.当前最为流行的支持异构的并行计算框架 OpenCL 和 CUDA 都采用它作为自己的平台模型。在 host & device 模式中,host 就像一个大管家,完成任务调度,节点通讯,负载均衡功能.因此 device 则只需 care 自己那部分的运算即可,无需 care 自身目前所处的环境.即实际运行环境对 device 是不可见的,device 不需要对运行环境的变化做出变化.这一点对于异构是至为重要的.Inferno 的架构非常适合采用 host & device 模式.根据前期对 Inferno的 namespace 和 styx 的调研,我们可以简单的用 bind 的命令将远程的 Inferno 节点的资源挂载在本地, 亦或是用 cpu 命令直接在远程端运行给定程序.所以可以选择一台节点作为 host, 其余节点作为 device.然后将 device 全部挂载在 host 上. 由 host 分发任务, 响应 device 请求, 进行 device 间调度等. 采用这种平台模型可以大大推进我们开发速度.
	为了提高异构性，防止在多节点并行计算时出现慢的节点拖累快的节点的情况。我们做了如下处理。首先任务分发的机制不是host主动分发给device,而是host将数据放入共享池，让device来抢占任务。其次，对任务进行细粒度划分。对于每个device,由于并行粒度细,各个 device 之间同步需求不大,且每次由 host 分配给它的任务并不繁重,可以在较短时间计算完成.再由抢占式任务分配机制,计算完成的节点把结果提交给 host 之后可以直接从 host 中抢占任务,而不是等待其余 device.如此实现,在一定程度上可以避免计算能力低的节点拖累计算能力高的节点,从而提高了异构性.
	通讯部分经过调研以及反复查阅手册，我们发现了Inferno自带了一个名为file2chan的工具。我们可以给定读方法和写方法，file2chan就会在内存中虚拟出一个虚拟文件。当我们对虚拟文件读时，就会触发先前给定的读方法，当我们对虚拟文件写时，就会触发先前给定的写方法。基于file2chan这种动态响应读写的性质，我们可以用它来做通讯池，动态响应host和device的请求，非常方便。然而file2chan还很粗糙，我们决定使用前对其进行封装。由于消息种类很多，如果都不加区分的放入消息池则必定会导致紊乱。所以我们决定设置操作码。例如device要把计算结果报给host,则先往消息池写入put，让消息池转换为put模式，然后再往消息池写入结果，此时消息池就会正确响应。再如device到消息池中抢占任务时，先往消息池写入get，然后再请求读，此时消息池就会把任务分配给他。如此封装，可以解决host,device通讯问题。然而这里出现了多节点并行访问一个文件的情况，需要做同步处理。对于读读，写写，读写互斥我们决定直接修改file2chan源码，在这个层次上解决。除此之外我们还需要保证事务的原子性。之前看到device抢占数据是要先写入get,再请求读。我们必须保证这两步连续执行，中间不能有其他节点操作乱入。这个问题我们决定在封装file2chan时，对其读写方法加锁同步处理。
	Inferno中一切皆文件，shell是对文件操作最好的工具。Inferno的中的shell非常强大，类似于python可以动态加载外部库。所以我们瞄准shell，做的是Inferno shell下的并行框架。经过调研，Inferno Shell中有很多强大的脚本工具，mount, bind, cpu等命令。再shell下就可以编写并行化代码。然而这很麻烦，要求用户对其充分了解。在我们的框架下，用户只要按照我们定义的规范写，自动就可实现并行化效果。为了达到这种效果，我们决定实现一个解释器，根据用户原来的串行脚本，我们可以翻译出两份代码，host代码和device代码。将各个节点互联后，在host节点上运行host代码并指定device节点的ip，就可以再各个device节点上launch device代码，进行加速。